{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a CNN model to classify an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "# import cifar10 dataset\n",
    "from keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle and split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train[0].shape)\n",
    "image = x_train[2]\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "print(np.unique(y_train,return_counts=True))\n",
    "print(np.unique(y_test,return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_test[0,0:2,0:2,])\n",
    "#print(y_train[1,0])\n",
    "#print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define number of classes\n",
    "num_classes = 10\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train2 = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test2 = keras.utils.to_categorical(y_test, num_classes)\n",
    "print(y_train2.shape)\n",
    "print(y_test2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert input train and test as float and devide it by 255 to have values between 0 and 1\n",
    "# each pixel can have values from 1 to 255 based on the colour and intensity\n",
    "x_train2 = x_train.astype('float32')\n",
    "x_test2 = x_test.astype('float32')\n",
    "x_train2 /= 255\n",
    "x_test2 /= 255\n",
    "print(x_train2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = x_train2.shape[1:]\n",
    "print(input_dim)\n",
    "print(type(input_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model = Sequential()\n",
    "\n",
    "# Create the model with two 32 convolution filters -> pooling layer -> two 64 conv filters -> pooling layer \n",
    "#                                                  -> flattening -> fully conncted layer \n",
    "\n",
    "# add first convolution layer with 32 filters of 3 x 3 size\n",
    "# image shape will be 32 x 32 x 10 as 10 filters are used with 'same' padding\n",
    "model.add(Conv2D(10, (3, 3), padding='same',input_shape=input_dim))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# add second convolution layer with 32 filters of 3 x 3 size\n",
    "# image shape will be 30 x 30 x 5 as 5 filters are used without padding\n",
    "#model.add(Conv2D(5, (3, 3)))\n",
    "#model.add(Activation('relu'))\n",
    "\n",
    "# add pooling layer with 2 x 2 pooling - default stride is same as pooling size\n",
    "# image shape will be 15 x 15 x 5 as pooling size and stride are 2\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Dropout(0.25))                       # drops 25% of units randomly for each epoch\n",
    "\n",
    "# add thrid convolution layer with 15 filters of 3 x 3 size\n",
    "# image shape will be 15 x 15 x 5 as 15 filters are used with 'same' padding\n",
    "#model.add(Conv2D(5, (3, 3), padding='same'))\n",
    "#model.add(Activation('relu'))\n",
    "\n",
    "# add fourth convolution layer with 64 filters of 3 x 3 size\n",
    "# image shape will be 14 x 14 x 5 as 5 filters are used without padding\n",
    "#model.add(Conv2D(5, (2, 2)))\n",
    "#model.add(Activation('relu'))\n",
    "\n",
    "# add pooling layer with 2 x 2 pooling\n",
    "# image shape will be 7 x 7 x 5 as pooling size and stride are 2\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Dropout(0.25))                       # drops 25% of units randomly for each epoch\n",
    "\n",
    "# add flattening layer to flattens into single dimensional\n",
    "# number of features will be = 7 x 7 x 5\n",
    "model.add(Flatten())                           \n",
    "\n",
    "# add hidden layer with 50 units with RELU as activation and dropout rate of 50%\n",
    "model.add(Dense(10))                          \n",
    "model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "\n",
    "# add output layers with number of classes in target variable with softmax as activation\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the batch size and epochs\n",
    "batch_size = 100\n",
    "epochs = 2\n",
    "# run the model with given data\n",
    "model.fit(x_train2, y_train2,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test2, y_test2),\n",
    "              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()\n",
    "# the input image size is 32 x 32 x 3\n",
    "# for first layer, 32 filters of 3x3 size applied across depth(3) of input image. \n",
    "# Hence, number of parameters will be 32 x 3 x 3 x 3 + 32 (Number of intercepts/filters) = 896\n",
    "# output size remains 32 x 32 as padding is done. the depth of impage is now 32 due to 32 number of filters\n",
    "# for second layer, 32 filters of 3x3 size applied across depth(32) of input image. \n",
    "# Hence, number of parameters will be 32 x 3 x 3 x 32 + 32 (Number of intercepts/filters) = 9248\n",
    "# output size changed to 30 x 30 as padding is not done. the depth of impage is now 32 due to 32 number of filters\n",
    "# after pooling done with 2 x 2 size with striding with same size, the image size got reduced to 15 x 15\n",
    "# for third layer with 64 filters: 64 x 3 x 3 x 32 + 64 = 18496. \n",
    "# output size remains 15 x 15 as padding is done. the depth of impage is now 64 due to 64 number of filters\n",
    "# for fourth layer with 64 filters: 64 x 3 x 3 x 64 + 64 = 36928. \n",
    "# output size remains 13 x 13 as padding is not done. the depth of impage is now 64 due to 64 number of filters\n",
    "# after pooling done with 2 x 2 size with striding with same size, the image size got reduced to 6 x 6\n",
    "# after flattening, the number of input nodes = 6 x 6 x 64 = 2304\n",
    "# as the number of nodes in hidden layer is 512, \n",
    "# the no. of parameters between input and hidder layer: 2304 x 512 + 512 = 1180160 (including 512 intercepts)\n",
    "# as the number of nodes in output layer is 10, \n",
    "# the no. of parameters between hidder and output layer: 512 x 10 + 10 = 530 (including 10 intercepts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get weights for any layer\n",
    "model.layers[0].get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get output of any layer\n",
    "model.layers[0].output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test\n",
    "y_pred = model.predict(x_test2)\n",
    "print(y_pred.shape)\n",
    "print(y_pred[0:5,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the Y_pred into single dimension\n",
    "y_pred2 = np.argmax(y_pred, axis=1)\n",
    "print(y_pred2.shape)\n",
    "print(y_pred2[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating using confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "print (confusion_matrix(y_test,y_pred2))\n",
    "print (classification_report(y_test,y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
