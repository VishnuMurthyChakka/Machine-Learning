{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "# from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "# import cifar10 dataset\n",
    "from keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n",
      "y_train shape: (50000, 1)\n",
      "y_test shape: (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "# shuffle and split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "print('y_train shape:', y_train.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(x_train[0].shape)\n",
    "image = x_train[2]\n",
    "plt.imshow(image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8), array([5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000, 5000],\n",
      "      dtype=int64))\n",
      "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9]), array([1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000],\n",
      "      dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(np.unique(y_train,return_counts=True))\n",
    "print(np.unique(y_test,return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[158 112  49]\n",
      "  [159 111  47]]\n",
      "\n",
      " [[152 112  51]\n",
      "  [151 110  40]]]\n"
     ]
    }
   ],
   "source": [
    "print(x_test[0,0:2,0:2,])\n",
    "#print(y_train[1,0])\n",
    "#print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 10)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# define number of classes\n",
    "num_classes = 10\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train2 = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test2 = keras.utils.to_categorical(y_test, num_classes)\n",
    "print(y_train2.shape)\n",
    "print(y_test2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "# convert input train and test as float and devide it by 255 to have values between 0 and 1\n",
    "# each pixel can have values from 1 to 255 based on the colour and intensity\n",
    "x_train2 = x_train.astype('float32')\n",
    "x_test2 = x_test.astype('float32')\n",
    "x_train2 /= 255\n",
    "x_test2 /= 255\n",
    "print(x_train2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32, 3)\n",
      "<class 'tuple'>\n"
     ]
    }
   ],
   "source": [
    "input_dim = x_train2.shape[1:]\n",
    "print(input_dim)\n",
    "print(type(input_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model = Sequential()\n",
    "\n",
    "# Create the model with two 32 convolution filters -> pooling layer -> two 64 conv filters -> pooling layer \n",
    "#                                                  -> flattening -> fully conncted layer \n",
    "\n",
    "# add first convolution layer with 32 filters of 3 x 3 size\n",
    "# image shape will be 32 x 32 x 10 as 10 filters are used with 'same' padding\n",
    "model.add(Conv2D(10, (3, 3), padding='same',input_shape=input_dim))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "# add second convolution layer with 32 filters of 3 x 3 size\n",
    "# image shape will be 30 x 30 x 5 as 5 filters are used without padding\n",
    "#model.add(Conv2D(5, (3, 3)))\n",
    "#model.add(Activation('relu'))\n",
    "\n",
    "# add pooling layer with 2 x 2 pooling - default stride is same as pooling size\n",
    "# image shape will be 15 x 15 x 5 as pooling size and stride are 2\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Dropout(0.25))                       # drops 25% of units randomly for each epoch\n",
    "\n",
    "# add thrid convolution layer with 15 filters of 3 x 3 size\n",
    "# image shape will be 15 x 15 x 5 as 15 filters are used with 'same' padding\n",
    "#model.add(Conv2D(5, (3, 3), padding='same'))\n",
    "#model.add(Activation('relu'))\n",
    "\n",
    "# add fourth convolution layer with 64 filters of 3 x 3 size\n",
    "# image shape will be 14 x 14 x 5 as 5 filters are used without padding\n",
    "#model.add(Conv2D(5, (2, 2)))\n",
    "#model.add(Activation('relu'))\n",
    "\n",
    "# add pooling layer with 2 x 2 pooling\n",
    "# image shape will be 7 x 7 x 5 as pooling size and stride are 2\n",
    "#model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "#model.add(Dropout(0.25))                       # drops 25% of units randomly for each epoch\n",
    "\n",
    "# add flattening layer to flattens into single dimensional\n",
    "# number of features will be = 7 x 7 x 5\n",
    "model.add(Flatten())                           \n",
    "\n",
    "# add hidden layer with 50 units with RELU as activation and dropout rate of 50%\n",
    "model.add(Dense(10))                          \n",
    "model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "\n",
    "# add output layers with number of classes in target variable with softmax as activation\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the model\n",
    "# initiate RMSprop optimizer\n",
    "opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "50000/50000 [==============================] - 18s 356us/step - loss: 2.2498 - accuracy: 0.1248 - val_loss: 2.2106 - val_accuracy: 0.1688\n",
      "Epoch 2/2\n",
      "50000/50000 [==============================] - 17s 346us/step - loss: 2.1749 - accuracy: 0.1779 - val_loss: 2.1479 - val_accuracy: 0.2118\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x218514e7fd0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define the batch size and epochs\n",
    "batch_size = 100\n",
    "epochs = 2\n",
    "# run the model with given data\n",
    "model.fit(x_train2, y_train2,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test2, y_test2),\n",
    "              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 10)        280       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 10)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 10)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2560)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                25610     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                110       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 26,000\n",
      "Trainable params: 26,000\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()\n",
    "# the input image size is 32 x 32 x 3\n",
    "# for first layer, 32 filters of 3x3 size applied across depth(3) of input image. \n",
    "# Hence, number of parameters will be 32 x 3 x 3 x 3 + 32 (Number of intercepts/filters) = 896\n",
    "# output size remains 32 x 32 as padding is done. the depth of impage is now 32 due to 32 number of filters\n",
    "# for second layer, 32 filters of 3x3 size applied across depth(32) of input image. \n",
    "# Hence, number of parameters will be 32 x 3 x 3 x 32 + 32 (Number of intercepts/filters) = 9248\n",
    "# output size changed to 30 x 30 as padding is not done. the depth of impage is now 32 due to 32 number of filters\n",
    "# after pooling done with 2 x 2 size with striding with same size, the image size got reduced to 15 x 15\n",
    "# for third layer with 64 filters: 64 x 3 x 3 x 32 + 64 = 18496. \n",
    "# output size remains 15 x 15 as padding is done. the depth of impage is now 64 due to 64 number of filters\n",
    "# for fourth layer with 64 filters: 64 x 3 x 3 x 64 + 64 = 36928. \n",
    "# output size remains 13 x 13 as padding is not done. the depth of impage is now 64 due to 64 number of filters\n",
    "# after pooling done with 2 x 2 size with striding with same size, the image size got reduced to 6 x 6\n",
    "# after flattening, the number of input nodes = 6 x 6 x 64 = 2304\n",
    "# as the number of nodes in hidden layer is 512, \n",
    "# the no. of parameters between input and hidder layer: 2304 x 512 + 512 = 1180160 (including 512 intercepts)\n",
    "# as the number of nodes in output layer is 10, \n",
    "# the no. of parameters between hidder and output layer: 512 x 10 + 10 = 530 (including 10 intercepts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[-0.09719947,  0.12310453,  0.00298954, -0.10722345, -0.00596494,\n",
       "          -0.09856968,  0.06461298,  0.1221973 ,  0.08826432, -0.02039197,\n",
       "           0.11277551, -0.12446858, -0.12601262, -0.01444677,  0.1400363 ,\n",
       "           0.09806473, -0.07937647,  0.02906777,  0.0787327 , -0.00046995,\n",
       "          -0.08936881,  0.14222652,  0.07164593,  0.10154688, -0.13192289,\n",
       "           0.07783452,  0.08297219,  0.08491747,  0.02095241, -0.00857404,\n",
       "          -0.12191526,  0.03462327],\n",
       "         [-0.00389243, -0.03419906,  0.07482473,  0.1406309 ,  0.01020346,\n",
       "           0.06998823, -0.06564525, -0.0042068 , -0.11174366,  0.04762294,\n",
       "          -0.11359771, -0.12697028, -0.11740825, -0.13842449, -0.0133414 ,\n",
       "           0.13542661, -0.01256989, -0.0554494 , -0.1035741 , -0.04378662,\n",
       "           0.11785579,  0.09435111, -0.06218493, -0.01594055,  0.13553922,\n",
       "          -0.03583952,  0.05977153, -0.00325366,  0.0565953 ,  0.03908509,\n",
       "          -0.04924184, -0.05740385],\n",
       "         [-0.09197115,  0.06391694,  0.02572855, -0.00521322,  0.0440184 ,\n",
       "           0.11558247, -0.01747091, -0.09812095,  0.07917354,  0.05398905,\n",
       "           0.13634416,  0.1239325 ,  0.02581888, -0.06969743,  0.07951907,\n",
       "           0.03280976,  0.07201581,  0.09146596, -0.09165453,  0.0807367 ,\n",
       "          -0.07491264,  0.02535579, -0.1016402 ,  0.05142134,  0.02342563,\n",
       "          -0.05027087,  0.13414322,  0.01400924, -0.04308601,  0.08433437,\n",
       "          -0.09067927,  0.03963299]],\n",
       "\n",
       "        [[ 0.09334207,  0.04114737,  0.0660369 ,  0.1151167 ,  0.15266602,\n",
       "          -0.05562175, -0.14750519,  0.01097008, -0.03949132,  0.14070526,\n",
       "           0.10249467, -0.06601804,  0.01573538,  0.10926082, -0.02810719,\n",
       "           0.08474824,  0.06316705,  0.13822287,  0.12381196,  0.01230422,\n",
       "          -0.12620996, -0.00317249, -0.06643948, -0.01864014, -0.11293316,\n",
       "          -0.11062372,  0.03078819, -0.13412979,  0.07165302,  0.1431751 ,\n",
       "          -0.00833187, -0.08548423],\n",
       "         [ 0.06635089,  0.08340834,  0.06130223, -0.12454063,  0.14740297,\n",
       "           0.09815315, -0.08041815,  0.13086656,  0.02766657,  0.09326903,\n",
       "          -0.04361575,  0.07490921, -0.07556801, -0.11183172, -0.12860446,\n",
       "          -0.08436453, -0.01829032,  0.02804744, -0.04844775,  0.04954943,\n",
       "          -0.13016607,  0.01726746, -0.04343076,  0.017811  , -0.04800033,\n",
       "          -0.09682517, -0.04771448, -0.02990794,  0.02723296,  0.10876866,\n",
       "          -0.06181408,  0.06983953],\n",
       "         [-0.08697602, -0.0681309 ,  0.02618051, -0.06184278,  0.05523555,\n",
       "           0.14674225,  0.0695907 ,  0.0757067 , -0.04338269, -0.14080511,\n",
       "          -0.02484587, -0.06509581, -0.12016135,  0.03950011,  0.00567958,\n",
       "           0.08562105, -0.10126785,  0.11246822, -0.11199646, -0.0808844 ,\n",
       "          -0.1103475 ,  0.06874263,  0.07008447, -0.07178524, -0.11767922,\n",
       "           0.12122907, -0.06112769,  0.07325658,  0.03399539,  0.0477648 ,\n",
       "          -0.1107578 ,  0.11889976]],\n",
       "\n",
       "        [[ 0.03093407,  0.04041847,  0.0408337 ,  0.12569144,  0.02485706,\n",
       "           0.06310741,  0.07111554, -0.12109451,  0.10179048,  0.01329212,\n",
       "          -0.0397757 , -0.14401469,  0.10734161,  0.0558337 ,  0.04375445,\n",
       "          -0.05867222,  0.1264122 , -0.01898131, -0.00379816, -0.01483087,\n",
       "           0.00376031, -0.02945273, -0.14848559,  0.06579276, -0.1404371 ,\n",
       "           0.0062959 , -0.00349757,  0.0782517 ,  0.11098965,  0.0617555 ,\n",
       "          -0.04550268, -0.09520474],\n",
       "         [-0.12463684,  0.07728496,  0.06164084,  0.11382412,  0.05296143,\n",
       "          -0.08335776,  0.10997319, -0.08416748,  0.00232861,  0.12959474,\n",
       "          -0.11787622,  0.04529644,  0.05014669,  0.13402402, -0.0344503 ,\n",
       "          -0.06303715,  0.02524454,  0.04150281,  0.13253498, -0.06961995,\n",
       "          -0.03818491, -0.09118171,  0.02003959,  0.08243094,  0.06231278,\n",
       "           0.10366506,  0.11108737, -0.06369019,  0.08218967, -0.08149742,\n",
       "          -0.08361745, -0.03636751],\n",
       "         [-0.10752336, -0.08386668,  0.06877381,  0.09583775,  0.07528314,\n",
       "           0.06484065, -0.02691   , -0.00921919,  0.1326842 , -0.13621058,\n",
       "           0.0438159 , -0.0152654 ,  0.07362433,  0.07637872,  0.10648936,\n",
       "           0.10047022,  0.10299237, -0.01892999,  0.13477528,  0.06126523,\n",
       "           0.07376132, -0.07767852, -0.10147136, -0.14059712,  0.04749585,\n",
       "           0.00267877,  0.11737024,  0.1414232 ,  0.02121042, -0.12615986,\n",
       "          -0.12956387,  0.03498376]]],\n",
       "\n",
       "\n",
       "       [[[ 0.13173965,  0.03196248, -0.00277462, -0.0374423 , -0.07367101,\n",
       "           0.01688393, -0.08034698, -0.02762013, -0.02351885,  0.03269256,\n",
       "          -0.09211288,  0.02354539, -0.09806905, -0.00451333, -0.13112558,\n",
       "           0.02345769, -0.04563563, -0.11430094,  0.05986584, -0.03254142,\n",
       "           0.0737162 , -0.0302492 , -0.03732262,  0.10479293,  0.09455616,\n",
       "           0.11802654, -0.05291718,  0.00629294, -0.14633973,  0.10385911,\n",
       "           0.10596986, -0.12598714],\n",
       "         [-0.02591679, -0.14072441,  0.13839521, -0.09835867, -0.09768831,\n",
       "           0.07616568,  0.10894447,  0.02321464, -0.13954897, -0.04158971,\n",
       "          -0.11868329, -0.02158907,  0.05344156,  0.00289035, -0.0450074 ,\n",
       "           0.17792019, -0.11909349, -0.11002113, -0.10464148,  0.11097915,\n",
       "          -0.01219276, -0.11182194, -0.10757885, -0.11268554,  0.15640464,\n",
       "          -0.02592332, -0.07221619,  0.07090009, -0.10126647, -0.01519501,\n",
       "           0.09153765, -0.09855676],\n",
       "         [ 0.09719748, -0.1515016 ,  0.04692993,  0.02501771, -0.02859465,\n",
       "          -0.00036405, -0.01046928,  0.08775765,  0.03820568,  0.05823851,\n",
       "           0.04720045,  0.12129346, -0.12552281, -0.01869565, -0.050729  ,\n",
       "           0.04248852,  0.11866983, -0.11946688,  0.12587449, -0.11484712,\n",
       "           0.12365895,  0.15346527,  0.10009357,  0.10323907,  0.0062086 ,\n",
       "          -0.01425353, -0.09605174, -0.11502731,  0.09762867, -0.11582758,\n",
       "           0.11501247, -0.00675648]],\n",
       "\n",
       "        [[-0.03841594, -0.08072072,  0.15002158,  0.11223394, -0.02955173,\n",
       "           0.14134338,  0.09327992, -0.09475963,  0.01407772,  0.08244506,\n",
       "           0.03109246,  0.00486511,  0.01215659,  0.13971646,  0.02599339,\n",
       "          -0.0683456 , -0.14807372,  0.14716695, -0.05221559,  0.0410243 ,\n",
       "           0.14045018,  0.0979837 , -0.00781503,  0.11468729,  0.09432387,\n",
       "           0.12553653,  0.00389878,  0.0399835 , -0.06640485,  0.12001744,\n",
       "          -0.03874351, -0.1380192 ],\n",
       "         [-0.00497757, -0.04968282, -0.02939455,  0.09791315, -0.03222437,\n",
       "          -0.10240483, -0.12224232, -0.08058929, -0.04703765, -0.04093719,\n",
       "          -0.0269071 , -0.00502626,  0.08234144,  0.05965856,  0.09387739,\n",
       "           0.05676351,  0.04937443,  0.01777363, -0.05124236, -0.07754005,\n",
       "           0.13614246,  0.12234239,  0.08467732, -0.12092347,  0.04868289,\n",
       "           0.16031304, -0.12321648, -0.13620041,  0.12492537,  0.0599301 ,\n",
       "           0.14560294, -0.05328787],\n",
       "         [-0.00705915, -0.00901764,  0.00807013, -0.05630657,  0.05570219,\n",
       "           0.15791336,  0.10505814,  0.02872622,  0.1097583 , -0.06367017,\n",
       "          -0.10005189,  0.0118741 , -0.02562996,  0.08705375, -0.03663756,\n",
       "           0.03185967,  0.11087149, -0.02887389, -0.01841758,  0.02118648,\n",
       "           0.10162015, -0.1108391 , -0.03938229, -0.02534667, -0.06833194,\n",
       "           0.0211477 , -0.09352469, -0.10030065,  0.10322547, -0.02585657,\n",
       "           0.04049681,  0.1364412 ]],\n",
       "\n",
       "        [[-0.01903904,  0.10143676, -0.08380093, -0.04407592, -0.00880327,\n",
       "           0.05090921,  0.10380433,  0.08680112,  0.11319929, -0.08341524,\n",
       "           0.13881697, -0.09590277, -0.10785707,  0.03969802, -0.10172553,\n",
       "          -0.11351447, -0.06352426, -0.08457912,  0.04704054,  0.07232106,\n",
       "           0.13068706,  0.01442089, -0.01625212,  0.06835572,  0.07641838,\n",
       "          -0.1190649 , -0.01674579,  0.04916411, -0.11802183,  0.07808509,\n",
       "          -0.07329415, -0.13864239],\n",
       "         [ 0.09445958,  0.13933651, -0.02366424, -0.09962276, -0.08172719,\n",
       "           0.03342729, -0.06421309, -0.10602862, -0.01574492,  0.05998797,\n",
       "          -0.00359487, -0.15343204, -0.00591095, -0.01291685, -0.00940302,\n",
       "          -0.01260652, -0.10769768, -0.11509713, -0.03080992, -0.0414548 ,\n",
       "           0.00160184, -0.03731738,  0.04149075,  0.01616604,  0.02672234,\n",
       "          -0.12902951, -0.05842014,  0.00943158,  0.11307342, -0.06297046,\n",
       "           0.04485237,  0.04673401],\n",
       "         [-0.01914666,  0.01031134, -0.17062804,  0.03994971, -0.08282024,\n",
       "           0.04459339, -0.02603403,  0.03026507,  0.05180176, -0.10996265,\n",
       "           0.10375599,  0.10389709, -0.01836623, -0.08406789, -0.12729499,\n",
       "          -0.02350781,  0.07647457,  0.15898782, -0.10808752,  0.1318453 ,\n",
       "           0.07534069,  0.09923298, -0.09802804, -0.00723632,  0.12002848,\n",
       "          -0.10483958, -0.06328385,  0.10912085,  0.04610563, -0.03468362,\n",
       "           0.07699825,  0.11620094]]],\n",
       "\n",
       "\n",
       "       [[[ 0.02371695, -0.09678712, -0.04945684, -0.0389595 , -0.08145606,\n",
       "          -0.05345159, -0.06680596,  0.02454087,  0.10181074,  0.01284323,\n",
       "          -0.02990455, -0.02092393, -0.00358261, -0.11497152,  0.05951637,\n",
       "          -0.00401453,  0.0071915 ,  0.1484925 ,  0.10771555, -0.12598731,\n",
       "          -0.04605878,  0.04022058, -0.00418187,  0.01279236, -0.00478097,\n",
       "          -0.03188294, -0.04736385,  0.09558745, -0.04597009,  0.05059267,\n",
       "          -0.0091482 ,  0.02674249],\n",
       "         [ 0.12920864, -0.13763171,  0.08702578,  0.09941999, -0.00553235,\n",
       "           0.08511455,  0.05775708, -0.14122172, -0.04149337, -0.0918196 ,\n",
       "          -0.10776044,  0.11872357,  0.00144433, -0.04338333,  0.01729871,\n",
       "          -0.06166973, -0.04533388,  0.02895646,  0.10188933,  0.00766949,\n",
       "           0.05765212, -0.1193435 , -0.06758661, -0.0918256 ,  0.02214247,\n",
       "          -0.04796571,  0.08251219,  0.01474161,  0.11730181, -0.12856743,\n",
       "           0.01438214,  0.08045242],\n",
       "         [-0.00884963,  0.03628277,  0.12402789,  0.09846818,  0.1105496 ,\n",
       "          -0.10416138, -0.10884055, -0.10636577, -0.09359419, -0.10993113,\n",
       "          -0.02450155,  0.08669929,  0.08354171,  0.11773444,  0.06912594,\n",
       "           0.01162751, -0.01317598, -0.0433254 ,  0.13890797,  0.00981977,\n",
       "          -0.07403225,  0.00113561,  0.00599785,  0.04604114,  0.13265781,\n",
       "           0.0185066 ,  0.12320141, -0.02841887, -0.00120804, -0.13273999,\n",
       "          -0.00151762,  0.01150682]],\n",
       "\n",
       "        [[-0.09320679,  0.12931463, -0.00684545, -0.11994938, -0.07404311,\n",
       "          -0.03386288,  0.10780937,  0.11985672,  0.02808857,  0.00426074,\n",
       "           0.03225689,  0.14284742,  0.12838899, -0.06343238, -0.11122032,\n",
       "           0.03899424, -0.02519607,  0.14727902, -0.11682928,  0.11278958,\n",
       "          -0.03491144, -0.12287503,  0.06487618,  0.10200299,  0.04925316,\n",
       "           0.05156206, -0.04904697,  0.09359594,  0.12376787, -0.04753984,\n",
       "           0.11950573, -0.02045121],\n",
       "         [ 0.02260042,  0.02440445,  0.05370232, -0.11121643, -0.01154878,\n",
       "          -0.12411381, -0.09353802,  0.03467377, -0.0903572 , -0.11337697,\n",
       "          -0.0899443 , -0.00937573,  0.02450199,  0.04625752, -0.10916824,\n",
       "          -0.08899757,  0.09259509, -0.12682216, -0.08888556, -0.13929336,\n",
       "           0.02459862,  0.12482012,  0.1155486 ,  0.0477945 , -0.09372515,\n",
       "           0.05683789, -0.07868061, -0.04433584,  0.07476138,  0.01556566,\n",
       "           0.07968665,  0.12682021],\n",
       "         [ 0.06111459,  0.04709827,  0.09654934, -0.14024898,  0.06301848,\n",
       "          -0.10678846, -0.07824309, -0.0211311 , -0.08878777,  0.03865655,\n",
       "           0.04958657,  0.12648332,  0.15215461, -0.06315199,  0.13405676,\n",
       "          -0.07171717,  0.05239431, -0.07273213, -0.0201617 , -0.12172665,\n",
       "           0.12682296,  0.13565224,  0.10534558,  0.0445687 ,  0.0498598 ,\n",
       "           0.00587542,  0.10461856, -0.05579088, -0.01388566, -0.14062059,\n",
       "           0.06455207,  0.08640317]],\n",
       "\n",
       "        [[ 0.12297721,  0.10203897, -0.16715434,  0.01165504, -0.05897298,\n",
       "          -0.10268128,  0.00389587,  0.01716769, -0.00680233, -0.08101183,\n",
       "           0.04671792,  0.11476287, -0.08397111, -0.13931915,  0.10552976,\n",
       "          -0.09971222,  0.04817898, -0.0572862 , -0.03085152,  0.16167079,\n",
       "           0.12648694, -0.08005589,  0.13308142, -0.0629188 ,  0.0649888 ,\n",
       "          -0.11165465, -0.01553184, -0.04089436, -0.12022086,  0.05828566,\n",
       "           0.03459199,  0.11241204],\n",
       "         [ 0.06073299,  0.00506024, -0.13381819, -0.02160999,  0.03169075,\n",
       "          -0.09405578,  0.10019585,  0.11664847,  0.03070156,  0.07614037,\n",
       "           0.13008557, -0.08348455,  0.11119903,  0.00992804,  0.04612533,\n",
       "          -0.07580403, -0.11168084, -0.10560598,  0.02314815, -0.02674701,\n",
       "           0.1059638 , -0.13073646,  0.12640262, -0.12265801, -0.12495928,\n",
       "           0.00810933,  0.00382758, -0.1181661 ,  0.0404518 ,  0.07260265,\n",
       "           0.0531284 , -0.09533183],\n",
       "         [-0.04905064,  0.04063284, -0.18707509,  0.05234782, -0.08866236,\n",
       "          -0.12689124,  0.00588041,  0.05983086,  0.07215882,  0.03625404,\n",
       "           0.03937159,  0.02379945,  0.03475644,  0.03416227,  0.09811836,\n",
       "          -0.09535524,  0.11107367, -0.05418074, -0.09077976,  0.03307544,\n",
       "          -0.0065498 , -0.05968012,  0.10871236,  0.00389612, -0.0405569 ,\n",
       "           0.01291708,  0.06255317,  0.02171386,  0.01111613, -0.01062569,\n",
       "          -0.11132085,  0.00976703]]]], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get weights for any layer\n",
    "model.layers[0].get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'strided_slice:0' shape=(32, 32, 32) dtype=float32>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get output of any layer\n",
    "model.layers[0].output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10)\n",
      "[[0.20791098 0.16587313 0.07654593 0.1494975  0.0453967  0.07653155\n",
      "  0.07894804 0.10185798 0.07185997 0.02557811]\n",
      " [0.06723771 0.20658918 0.03580806 0.02194618 0.01833847 0.00991812\n",
      "  0.01394072 0.01742824 0.35791096 0.25088236]\n",
      " [0.10172568 0.14669454 0.03055593 0.02654443 0.02249378 0.01707674\n",
      "  0.01919279 0.02885925 0.4262     0.18065685]\n",
      " [0.32484365 0.14879444 0.04847208 0.08345231 0.03562198 0.02565824\n",
      "  0.02499546 0.06612279 0.2075023  0.0345368 ]\n",
      " [0.16296154 0.08615512 0.08740304 0.11959009 0.08420058 0.12367\n",
      "  0.14203303 0.12491816 0.03352776 0.03554069]]\n"
     ]
    }
   ],
   "source": [
    "# predict on test\n",
    "y_pred = model.predict(x_test2)\n",
    "print(y_pred.shape)\n",
    "print(y_pred[0:5,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000,)\n",
      "[0 8 8 0 0]\n"
     ]
    }
   ],
   "source": [
    "# convert the Y_pred into single dimension\n",
    "y_pred2 = np.argmax(y_pred, axis=1)\n",
    "print(y_pred2.shape)\n",
    "print(y_pred2[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[537  75   0   0   0   7  31  38 243  69]\n",
      " [194 416   0   0   0  33  56  29 106 166]\n",
      " [528  71   2   0   0  70 154  90  50  35]\n",
      " [400  84   4   0   0 158 150 105  25  74]\n",
      " [477  54   2   0   0  52 223 130  25  37]\n",
      " [387  72   4   0   0 236 142 105  22  32]\n",
      " [318  94   3   1   0 124 314  84  10  52]\n",
      " [350  78   1   1   0  59  97 234  27 153]\n",
      " [300 119   0   0   0  17  15   9 434 106]\n",
      " [182 156   2   0   0  22  43  36 125 434]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.15      0.54      0.23      1000\n",
      "           1       0.34      0.42      0.37      1000\n",
      "           2       0.11      0.00      0.00      1000\n",
      "           3       0.00      0.00      0.00      1000\n",
      "           4       0.00      0.00      0.00      1000\n",
      "           5       0.30      0.24      0.27      1000\n",
      "           6       0.26      0.31      0.28      1000\n",
      "           7       0.27      0.23      0.25      1000\n",
      "           8       0.41      0.43      0.42      1000\n",
      "           9       0.37      0.43      0.40      1000\n",
      "\n",
      "    accuracy                           0.26     10000\n",
      "   macro avg       0.22      0.26      0.22     10000\n",
      "weighted avg       0.22      0.26      0.22     10000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vishnu Murthy Chakka\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1268: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Evaluating using confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "print (confusion_matrix(y_test,y_pred2))\n",
    "print (classification_report(y_test,y_pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
